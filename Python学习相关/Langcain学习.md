# Langchainå­¦ä¹ 

--------

**LangChain**æ˜¯ä¸€ä¸ªæ¡†æ¶ï¼Œç”¨äºå¼€å‘ç”±å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰é©±åŠ¨çš„åº”ç”¨ç¨‹åºã€‚

LangChain ç®€åŒ–äº† LLM åº”ç”¨ç¨‹åºç”Ÿå‘½å‘¨æœŸçš„æ¯ä¸ªé˜¶æ®µï¼š

- **å¼€å‘**ï¼šä½¿ç”¨LangChainçš„å¼€æº[æ„å»ºå—](https://python.langchain.com/v0.1/docs/expression_language/)å’Œ[ç»„ä»¶](https://python.langchain.com/v0.1/docs/modules/)æ„å»ºåº”ç”¨ç¨‹åºã€‚ä½¿ç”¨[ç¬¬ä¸‰æ–¹é›†æˆ](https://python.langchain.com/v0.1/docs/integrations/platforms/)å’Œ[æ¨¡æ¿](https://python.langchain.com/v0.1/docs/templates/)å¼€å§‹è¿è¡Œã€‚
- **ç”Ÿäº§åŒ–**ï¼šä½¿ç”¨ [LangSmith](https://python.langchain.com/v0.1/docs/langsmith/) æ£€æŸ¥ã€ç›‘æ§å’Œè¯„ä¼°æ‚¨çš„é“¾æ¡ï¼Œä»¥ä¾¿æ‚¨å¯ä»¥è‡ªä¿¡åœ°æŒç»­ä¼˜åŒ–å’Œéƒ¨ç½²ã€‚
- **éƒ¨ç½²**ï¼šä½¿ç”¨ [LangServe](https://python.langchain.com/v0.1/docs/langserve/) å°†ä»»ä½•é“¾è½¬æ¢ä¸º APIã€‚

LLM æ”¯æŒçš„æœ€å¼ºå¤§çš„åº”ç”¨ç¨‹åºä¹‹ä¸€æ˜¯å¤æ‚çš„é—®ç­” ï¼ˆQ&Aï¼‰ èŠå¤©æœºå™¨äººã€‚è¿™äº›åº”ç”¨ç¨‹åºå¯ä»¥å›ç­”æœ‰å…³ç‰¹å®šæºä¿¡æ¯çš„é—®é¢˜ã€‚è¿™äº›åº”ç”¨ç¨‹åºä½¿ç”¨ä¸€ç§ç§°ä¸ºæ£€ç´¢å¢å¼ºç”Ÿæˆ ï¼ˆRAGï¼‰ çš„æŠ€æœ¯ã€‚

### ä»€ä¹ˆæ˜¯RAGï¼Ÿ

RAG æ˜¯ä¸€ç§ä½¿ç”¨é¢å¤–æ•°æ®å¢å¼º LLM çŸ¥è¯†çš„æŠ€æœ¯ã€‚

LLM å¯ä»¥å¯¹å¹¿æ³›çš„ä¸»é¢˜è¿›è¡Œæ¨ç†ï¼Œä½†ä»–ä»¬çš„çŸ¥è¯†ä»…é™äºä»–ä»¬æ¥å—åŸ¹è®­çš„ç‰¹å®šæ—¶é—´ç‚¹ä¹‹å‰çš„å…¬å…±æ•°æ®ã€‚å¦‚æœè¦æ„å»ºå¯ä»¥æ¨ç†ç§æœ‰æ•°æ®æˆ–æ¨¡å‹æˆªæ­¢æ—¥æœŸåå¼•å…¥çš„æ•°æ®çš„ AI åº”ç”¨ç¨‹åºï¼Œåˆ™éœ€è¦ä½¿ç”¨æ¨¡å‹æ‰€éœ€çš„ç‰¹å®šä¿¡æ¯æ¥å¢å¼ºæ¨¡å‹çš„çŸ¥è¯†ã€‚å¼•å…¥é€‚å½“ä¿¡æ¯å¹¶å°†å…¶æ’å…¥æ¨¡å‹æç¤ºç¬¦çš„è¿‡ç¨‹ç§°ä¸ºæ£€ç´¢å¢å¼ºç”Ÿæˆ ï¼ˆRAGï¼‰ã€‚

LangChainæœ‰è®¸å¤šç»„ä»¶ï¼Œæ—¨åœ¨å¸®åŠ©æ„å»ºQ&Aåº”ç”¨ç¨‹åºï¼Œä»¥åŠæ›´æ™®éçš„RAGåº”ç”¨ç¨‹åºã€‚

## RAG æ¶æ„

å…¸å‹çš„ RAG åº”ç”¨ç¨‹åºæœ‰ä¸¤ä¸ªä¸»è¦ç»„ä»¶ï¼š

**ç´¢å¼•**ï¼šç”¨äºä»æºå¼•å…¥æ•°æ®å¹¶å¯¹å…¶è¿›è¡Œç´¢å¼•çš„ç®¡é“ã€‚*è¿™é€šå¸¸å‘ç”Ÿåœ¨ç¦»çº¿çŠ¶æ€ã€‚*

**æ£€ç´¢å’Œç”Ÿæˆ**ï¼šå®é™…çš„ RAG é“¾ï¼Œå®ƒåœ¨è¿è¡Œæ—¶æ¥å—ç”¨æˆ·æŸ¥è¯¢å¹¶ä»ç´¢å¼•ä¸­æ£€ç´¢ç›¸å…³æ•°æ®ï¼Œç„¶åå°†å…¶ä¼ é€’ç»™æ¨¡å‹ã€‚

ä»åŸå§‹æ•°æ®åˆ°ç­”æ¡ˆæœ€å¸¸è§çš„å®Œæ•´åºåˆ—å¦‚ä¸‹æ‰€ç¤ºï¼š

#### ç´¢å¼•

1. **åŠ è½½**ï¼šé¦–å…ˆæˆ‘ä»¬éœ€è¦åŠ è½½æ•°æ®ã€‚è¿™æ˜¯ä½¿ç”¨ [DocumentLoaders](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/) å®Œæˆçš„ã€‚
2. **æ‹†åˆ†**ï¼š[æ–‡æœ¬æ‹†åˆ†å™¨å°†](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/)å¤§å—æ‹†åˆ†ä¸ºæ›´å°çš„å—ã€‚è¿™å¯¹äºç´¢å¼•æ•°æ®å’Œå°†æ•°æ®ä¼ é€’åˆ°æ¨¡å‹éƒ½å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºå¤§å—æ›´éš¾æœç´¢ï¼Œå¹¶ä¸”ä¸é€‚åˆæ¨¡å‹çš„æœ‰é™ä¸Šä¸‹æ–‡çª—å£ã€‚`Documents`
3. **å­˜å‚¨**ï¼šæˆ‘ä»¬éœ€è¦æŸä¸ªåœ°æ–¹æ¥å­˜å‚¨å’Œç´¢å¼•æˆ‘ä»¬çš„æ‹†åˆ†ï¼Œä»¥ä¾¿ä»¥åå¯ä»¥æœç´¢å®ƒä»¬ã€‚è¿™é€šå¸¸æ˜¯ä½¿ç”¨ [VectorStore](https://python.langchain.com/v0.1/docs/modules/data_connection/vectorstores/) å’Œ [Embeddings](https://python.langchain.com/v0.1/docs/modules/data_connection/text_embedding/) æ¨¡å‹å®Œæˆçš„ã€‚

![image-20240610205424416](https://stupid-blog-img.oss-cn-beijing.aliyuncs.com/Blog/image-20240610205424416.png)

#### æ£€ç´¢å’Œç”Ÿæˆ

1. **æ£€ç´¢**ï¼šç»™å®šç”¨æˆ·è¾“å…¥ï¼Œä½¿ç”¨ [Retriever](https://python.langchain.com/v0.1/docs/modules/data_connection/retrievers/) ä»å­˜å‚¨ä¸­æ£€ç´¢ç›¸å…³æ‹†åˆ†ã€‚
2. **ç”Ÿæˆ**ï¼š[ChatModel](https://python.langchain.com/v0.1/docs/modules/model_io/chat/) / [LLM](https://python.langchain.com/v0.1/docs/modules/model_io/llms/) ä½¿ç”¨åŒ…å«é—®é¢˜å’Œæ£€ç´¢æ•°æ®çš„æç¤ºç”Ÿæˆç­”æ¡ˆ

![image-20240610205525304](https://stupid-blog-img.oss-cn-beijing.aliyuncs.com/Blog/image-20240610205525304.png)

## Langchain

LangChainåº”ç”¨ç¨‹åºçš„æ ¸å¿ƒæ„å»ºå—æ˜¯LLMChainã€‚è¿™ç»“åˆäº†ä¸‰ä»¶äº‹ï¼š

1.   1.LLMï¼šè¯­è¨€æ¨¡å‹æ˜¯è¿™é‡Œçš„æ ¸å¿ƒæ¨ç†å¼•æ“ã€‚ä¸ºäº†ä½¿ç”¨ LangChainï¼Œæ‚¨éœ€è¦äº†è§£ä¸åŒç±»å‹çš„è¯­è¨€æ¨¡å‹ä»¥åŠå¦‚ä½•ä½¿ç”¨å®ƒä»¬ã€‚
2.   2.æç¤ºæ¨¡æ¿ï¼šè¿™ä¸ºè¯­è¨€æ¨¡å‹æä¾›è¯´æ˜ã€‚è¿™æ§åˆ¶è¯­è¨€æ¨¡å‹è¾“å‡ºçš„å†…å®¹ï¼Œå› æ­¤äº†è§£å¦‚ä½•æ„é€ æç¤ºå’Œä¸åŒçš„æç¤ºç­–ç•¥è‡³å…³é‡è¦ã€‚
3.   3.è¾“å‡ºè§£æå™¨ï¼šè¿™äº›å°†æ¥è‡ªLLMçš„åŸå§‹å“åº”è½¬æ¢ä¸ºæ›´å¯è¡Œçš„æ ¼å¼ï¼Œä»è€Œå¯ä»¥è½»æ¾ä½¿ç”¨ä¸‹æ¸¸çš„è¾“å‡ºã€‚

æˆ‘ä»¬å°†å•ç‹¬ä»‹ç»è¿™ä¸‰ä¸ªç»„ä»¶ï¼Œç„¶åä»‹ç»ç»„åˆæ‰€æœ‰è¿™äº›ç»„ä»¶çš„LLMChainã€‚

äº†è§£è¿™äº›æ¦‚å¿µå°†ä¸ºæ‚¨èƒ½å¤Ÿä½¿ç”¨å’Œè‡ªå®šä¹‰ LangChain åº”ç”¨ç¨‹åºåšå¥½å‡†å¤‡ã€‚

å¤§å¤šæ•°LangChainåº”ç”¨ç¨‹åºéƒ½å…è®¸æ‚¨é…ç½®LLMå’Œ/æˆ–ä½¿ç”¨çš„æç¤ºï¼Œå› æ­¤çŸ¥é“å¦‚ä½•åˆ©ç”¨è¿™ä¸€ç‚¹å°†æ˜¯ä¸€ä¸ªå¾ˆå¤§çš„æ¨åŠ¨å› ç´ ã€‚

## LLMs

æœ‰ä¸¤ç§ç±»å‹çš„è¯­è¨€æ¨¡å‹ï¼Œåœ¨LangChainä¸­ç§°ä¸ºï¼š

- llmsï¼šè¿™æ˜¯ä¸€ä¸ªè¯­è¨€æ¨¡å‹ï¼Œå®ƒå°†å­—ç¬¦ä¸²ä½œä¸ºè¾“å…¥å¹¶è¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²
- chat_modelsï¼šè¿™æ˜¯ä¸€ç§è¯­è¨€æ¨¡å‹ï¼Œå®ƒå°†æ¶ˆæ¯åˆ—è¡¨ä½œä¸ºè¾“å…¥å¹¶è¿”å›æ¶ˆæ¯

LLM çš„è¾“å…¥/è¾“å‡ºç®€å•æ˜“æ‡‚ - ä¸€ä¸ªå­—ç¬¦ä¸²ã€‚

ä½†æ˜¯chat_modelså‘¢ï¼Ÿ

é‚£é‡Œçš„è¾“å…¥æ˜¯ChatMessageçš„åˆ—è¡¨ ï¼Œè¾“å‡ºæ˜¯å•ä¸ªChatMessage .

ä¸€ä¸ªChatMessageæœ‰ä¸¤ä¸ªå¿…éœ€çš„ç»„ä»¶ï¼š

- > content ï¼šè¿™æ˜¯æ¶ˆæ¯çš„å†…å®¹ã€‚

- > role ï¼šè¿™æ˜¯æ¥è‡ªçš„ ChatMessage å®ä½“çš„è§’è‰²ã€‚

LangChain æä¾›äº†å‡ ä¸ªå¯¹è±¡æ¥è½»æ¾åŒºåˆ†ä¸åŒçš„è§’è‰²ï¼š

- HumanMessage ï¼š ChatMessageæ¥è‡ªäººç±»/ç”¨æˆ·ã€‚
- AIMessage ï¼š ChatMessageæ¥è‡ªAI/åŠ©æ‰‹ã€‚
- SystemMessage ï¼šæ¥è‡ªç³»ç»Ÿçš„ChatMessage ã€‚
- FunctionMessage ï¼šæ¥è‡ªå‡½æ•°è°ƒç”¨çš„ChatMessage ã€‚

LangChain ä¸ºä¸¤è€…å…¬å¼€äº†ä¸€ä¸ªæ ‡å‡†æ¥å£ï¼Œä½†äº†è§£è¿™ç§å·®å¼‚ä»¥ä¾¿ä¸ºç»™å®šè¯­è¨€æ¨¡å‹æ„é€ æç¤ºå¾ˆæœ‰ç”¨ã€‚LangChain å…¬å¼€çš„æ ‡å‡†æ¥å£æœ‰ä¸¤ç§æ–¹æ³•ï¼š

- predict ï¼šæ¥å—å­—ç¬¦ä¸²ï¼Œè¿”å›å­—ç¬¦ä¸²
- predict_messages ï¼šæ¥æ”¶æ¶ˆæ¯åˆ—è¡¨ï¼Œè¿”å›æ¶ˆæ¯ã€‚

å¯¹äºè¿™ä¸¤ç§æ–¹æ³•ï¼Œè¿˜å¯ä»¥å°†å‚æ•°ä½œä¸ºå…³é”®å­—å‚æ•°ä¼ å…¥ã€‚

ä¾‹å¦‚ï¼Œæ‚¨å¯ä»¥ä¼ å…¥ temperature=0 ä»¥æ ¹æ®å¯¹è±¡çš„é…ç½®è°ƒæ•´ä½¿ç”¨çš„æ¸©åº¦ã€‚åœ¨è¿è¡Œæ—¶ä¼ å…¥çš„ä»»ä½•å€¼éƒ½å°†å§‹ç»ˆè¦†ç›–å¯¹è±¡é…ç½®çš„å†…å®¹ã€‚

###  æç¤ºæ¨¡æ¿

å¤§å¤šæ•°LLMåº”ç”¨ç¨‹åºä¸ä¼šå°†ç”¨æˆ·è¾“å…¥ç›´æ¥ä¼ é€’åˆ°LLMã€‚

é€šå¸¸ï¼Œä»–ä»¬ä¼šå°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°ç§°ä¸ºæç¤ºæ¨¡æ¿çš„è¾ƒå¤§æ–‡æœ¬ä¸­ï¼Œè¯¥æ–‡æœ¬ä¸ºæ‰‹å¤´çš„ç‰¹å®šä»»åŠ¡æä¾›é¢å¤–çš„ä¸Šä¸‹æ–‡ã€‚

```python
from langchain.prompts import PromptTemplate

prompt = PromptTemplate.from_template("What is a good name for a company that makes {product}?")
prompt.format(product="colorful socks")
```

â€‹    æç¤ºæ¨¡æ¿è¿˜å¯ç”¨äºç”Ÿæˆæ¶ˆæ¯åˆ—è¡¨ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæç¤ºä¸ä»…åŒ…å«æœ‰å…³å†…å®¹çš„ä¿¡æ¯ï¼Œè¿˜åŒ…å«æ¯æ¡æ¶ˆæ¯ï¼ˆå…¶è§’è‰²ï¼Œå…¶åœ¨åˆ—è¡¨ä¸­çš„ä½ç½®ç­‰ï¼‰åœ¨è¿™é‡Œï¼Œæœ€å¸¸å‘ç”Ÿçš„æ˜¯èŠå¤©æç¤ºæ¨¡æ¿æ˜¯èŠå¤©æ¶ˆæ¯æ¨¡æ¿çš„åˆ—è¡¨ã€‚æ¯ä¸ªèŠå¤©æ¶ˆæ¯æ¨¡æ¿éƒ½åŒ…å«æœ‰å…³å¦‚ä½•æ ¼å¼åŒ–è¯¥èŠå¤©æ¶ˆæ¯çš„è¯´æ˜         - å®ƒçš„è§’è‰²ï¼Œç„¶åæ˜¯å®ƒçš„å†…å®¹ã€‚      

### è¾“å‡ºè§£æå™¨      

 è¾“å‡ºè§£æå™¨å°†LLMçš„åŸå§‹è¾“å‡ºè½¬æ¢ä¸ºå¯ä»¥åœ¨ä¸‹æ¸¸ä½¿ç”¨çš„æ ¼å¼ã€‚è¾“å‡ºåˆ†æå™¨çš„ä¸»è¦ç±»å‹å¾ˆå°‘ï¼ŒåŒ…æ‹¬ï¼š      

 ä»LLMè½¬æ¢æ–‡æœ¬->ç»“æ„åŒ–ä¿¡æ¯ï¼ˆä¾‹å¦‚JSONï¼‰      

 å°†èŠå¤©æ¶ˆæ¯è½¬æ¢ä¸ºå­—ç¬¦ä¸² 

 å°†è°ƒç”¨è¿”å›çš„é¢å¤–ä¿¡æ¯è½¬æ¢ä¸ºå­—ç¬¦ä¸²ï¼Œè€Œä¸æ˜¯æ¶ˆæ¯ï¼ˆå¦‚ OpenAI å‡½æ•°è°ƒç”¨ï¼‰ã€‚ 

###   å¤§è¯­è¨€æ¨¡å‹é“¾

æˆ‘ä»¬ç°åœ¨å¯ä»¥å°†æ‰€æœ‰è¿™äº›ç»„åˆæˆä¸€ä¸ªé“¾ã€‚æ­¤é“¾å°†è·å–è¾“å…¥å˜é‡ï¼Œå°†è¿™äº›å˜é‡ä¼ é€’ç»™æç¤ºæ¨¡æ¿ä»¥åˆ›å»ºæç¤ºï¼Œå°†æç¤ºä¼ é€’ç»™ LLMï¼Œç„¶åé€šè¿‡ï¼ˆå¯é€‰ï¼‰è¾“å‡ºåˆ†æå™¨ä¼ é€’è¾“å‡ºã€‚è¿™æ˜¯æ†ç»‘æ¨¡å—åŒ–é€»è¾‘çš„ä¾¿æ·æ–¹æ³•ã€‚è®©æˆ‘ä»¬çœ‹çœ‹å®ƒçš„å®é™…æ•ˆæœï¼

# langchain æç¤ºè¯ 

--------

ä»»ä½•è¯­è¨€æ¨¡å‹åº”ç”¨ç¨‹åºçš„æ ¸å¿ƒå…ƒç´ éƒ½æ˜¯...æ¨¡å‹ã€‚
LangChainä¸ºæ‚¨æä¾›äº†ä¸ä»»ä½•è¯­è¨€æ¨¡å‹äº¤äº’çš„æ„å»ºå—ã€‚
Promptsï¼šæ¨¡æ¿åŒ–ã€åŠ¨æ€é€‰æ‹©å’Œç®¡ç†æ¨¡å‹è¾“å…¥
è¯­è¨€æ¨¡å‹ï¼šé€šè¿‡é€šç”¨æ¥å£è°ƒç”¨è¯­è¨€æ¨¡å‹
è¾“å‡ºè§£æå™¨ï¼šä»æ¨¡å‹è¾“å‡ºä¸­æå–ä¿¡æ¯

##  Prompts

è¯­è¨€æ¨¡å‹æç¤ºæ˜¯ç”¨æˆ·æä¾›çš„ä¸€ç»„æŒ‡ä»¤æˆ–è¾“å…¥ï¼Œç”¨äºæŒ‡å¯¼æ¨¡å‹çš„å“åº”ï¼Œå¸®åŠ©å®ƒç†è§£ä¸Šä¸‹æ–‡å¹¶ç”Ÿæˆç›¸å…³ä¸”è¿è´¯çš„åŸºäºè¯­è¨€çš„è¾“å‡ºï¼Œä¾‹å¦‚å›ç­”é—®é¢˜ã€å®Œæˆå¥å­æˆ–å‚ä¸å¯¹è¯ã€‚
LangChain æä¾›äº†å¤šä¸ªç±»å’Œå‡½æ•°æ¥å¸®åŠ©æ„é€ å’Œä½¿ç”¨æç¤ºã€‚
æç¤ºæ¨¡æ¿ï¼šå‚æ•°åŒ–æ¨¡å‹è¾“å…¥
ç¤ºä¾‹é€‰æ‹©å™¨ï¼šåŠ¨æ€é€‰æ‹©è¦åŒ…å«åœ¨æç¤ºä¸­çš„ç¤ºä¾‹

###  PromptTemplate

æç¤ºæ¨¡æ¿æ˜¯ä¸ºè¯­è¨€æ¨¡å‹ç”Ÿæˆæç¤ºçš„é¢„å®šä¹‰é…æ–¹ã€‚
æ¨¡æ¿å¯èƒ½åŒ…æ‹¬è¯´æ˜ã€å‡ ä¸ªé•œå¤´ç¤ºä¾‹ä»¥åŠé€‚åˆç»™å®šä»»åŠ¡çš„ç‰¹å®šä¸Šä¸‹æ–‡å’Œé—®é¢˜ã€‚
LangChain æä¾›äº†åˆ›å»ºå’Œä½¿ç”¨æç¤ºæ¨¡æ¿çš„å·¥å…·ã€‚
LangChain è‡´åŠ›äºåˆ›å»ºä¸æ¨¡å‹æ— å…³çš„æ¨¡æ¿ï¼Œä»¥ä¾¿è½»æ¾åœ°è·¨ä¸åŒè¯­è¨€æ¨¡å‹é‡ç”¨ç°æœ‰æ¨¡æ¿ã€‚
é€šå¸¸ï¼Œè¯­è¨€æ¨¡å‹å¸Œæœ›æç¤ºæ˜¯å­—ç¬¦ä¸²æˆ–èŠå¤©æ¶ˆæ¯åˆ—è¡¨ã€‚

```python
from langchain import PromptTemplate #ç”¨äº PromptTemplate ä¸ºå­—ç¬¦ä¸²æç¤ºåˆ›å»ºæ¨¡æ¿ã€‚

#é»˜è®¤æƒ…å†µä¸‹ï¼Œ PromptTemplate ä½¿ç”¨ Python çš„ str.format è¯­æ³•è¿›è¡Œæ¨¡æ¿åŒ–;ä½†æ˜¯å¯ä»¥ä½¿ç”¨å…¶ä»–æ¨¡æ¿è¯­æ³•ï¼ˆä¾‹å¦‚ï¼Œ jinja2 ï¼‰
prompt_template = PromptTemplate.from_template(
    "Tell me a {adjective} joke about {content}."
)
prompt_template.format(adjective="funny", content="chickens")
```

```python
from langchain import PromptTemplate

#å¯¹äºå…¶ä»–éªŒè¯ï¼Œè¯·æ˜¾å¼æŒ‡å®š input_variables ã€‚
#åœ¨å®ä¾‹åŒ–æœŸé—´ï¼Œè¿™äº›å˜é‡å°†ä¸æ¨¡æ¿å­—ç¬¦ä¸²ä¸­å­˜åœ¨çš„å˜é‡è¿›è¡Œæ¯”è¾ƒï¼Œå¦‚æœä¸åŒ¹é…ï¼Œåˆ™ä¼šå¼•å‘å¼‚å¸¸;
invalid_prompt = PromptTemplate(
    input_variables=["adjective"],
    template="Tell me a {adjective} joke about {content}."
)
```

èŠå¤©æ¨¡å‹çš„æç¤ºæ˜¯èŠå¤©æ¶ˆæ¯åˆ—è¡¨ã€‚
æ¯æ¡èŠå¤©æ¶ˆæ¯éƒ½ä¸å†…å®¹ç›¸å…³è”ï¼Œä»¥åŠä¸€ä¸ªåä¸º role çš„é™„åŠ å‚æ•°ã€‚ä¾‹å¦‚ï¼Œåœ¨ OpenAI èŠå¤©å®Œæˆ API ä¸­ï¼ŒèŠå¤©æ¶ˆæ¯å¯ä»¥ä¸ AI åŠ©æ‰‹ã€äººå‘˜æˆ–ç³»ç»Ÿè§’è‰²ç›¸å…³è”ã€‚

```python
from langchain.prompts import ChatPromptTemplate

#ChatPromptTemplate.from_messages æ¥å—å„ç§æ¶ˆæ¯è¡¨ç¤ºå½¢å¼ã€‚
template = ChatPromptTemplate.from_messages([
    ("system", "You are a helpful AI bot. Your name is {name}."),
    ("human", "Hello, how are you doing?"),
    ("ai", "I'm doing well, thanks!"),
    ("human", "{user_input}"),
])

messages = template.format_messages(
    name="Bob",
    user_input="What is your name?"
)
```

é™¤äº†ä½¿ç”¨ä¸Šä¸€ä¸ªä»£ç å—ä¸­ä½¿ç”¨çš„ï¼ˆç±»å‹ã€å†…å®¹ï¼‰çš„ 2 å…ƒç»„è¡¨ç¤ºå½¢å¼å¤–ï¼Œ
è¿˜å¯ä»¥ä¼ å…¥ or BaseMessage çš„ MessagePromptTemplate å®ä¾‹ã€‚

```python
from langchain.prompts import ChatPromptTemplate
from langchain.prompts.chat import SystemMessage, HumanMessagePromptTemplate

template = ChatPromptTemplate.from_messages(
    [
        SystemMessage(
            content=(
                "You are a helpful assistant that re-writes the user's text to "
                "sound more upbeat."
            )
        ),
        HumanMessagePromptTemplate.from_template("{text}"),
    ]
)

from langchain.chat_models import ChatOpenAI

#è®¾ç½®ä»£ç†
import os
os.environ['http_proxy'] = 'http://127.0.0.1:10809'
os.environ['https_proxy'] = 'http://127.0.0.1:10809'

llm = ChatOpenAI()
llm(template.format_messages(text='i dont like eating tasty things.'))
```

### è‡ªå®šä¹‰æç¤ºæ¨¡æ¿

LangChain æä¾›äº†ä¸€ç»„é»˜è®¤çš„æç¤ºæ¨¡æ¿ï¼Œå¯ç”¨äºä¸ºå„ç§ä»»åŠ¡ç”Ÿæˆæç¤ºã€‚ä½†æ˜¯ï¼Œåœ¨æŸäº›æƒ…å†µä¸‹ï¼Œé»˜è®¤æç¤ºæ¨¡æ¿å¯èƒ½æ— æ³•æ»¡è¶³æ‚¨çš„éœ€æ±‚ã€‚ä¾‹å¦‚ï¼Œæ‚¨å¯èƒ½å¸Œæœ›åˆ›å»ºä¸€ä¸ªæç¤ºæ¨¡æ¿ï¼Œå…¶ä¸­åŒ…å«è¯­è¨€æ¨¡å‹çš„ç‰¹å®šåŠ¨æ€è¯´æ˜ã€‚åœ¨è¿™ç§æƒ…å†µä¸‹ï¼Œæ‚¨å¯ä»¥åˆ›å»ºè‡ªå®šä¹‰æç¤ºæ¨¡æ¿ã€‚

æˆ‘ä»¬åœ¨å†™æç¤ºè¯æ¨¡æ¿çš„æ—¶å€™ï¼Œæœ‰äº›æƒ…å†µä¸‹ï¼Œæˆ‘ä»¬éœ€è¦ç»™å‡ºä¸€äº›ä¾‹å­ï¼Œè¿™æ ·å¯ä»¥è®©æ¨¡å‹æ›´å¥½çš„ç†è§£æˆ‘ä»¬çš„æ„å›¾ã€‚

```python
from langchain.prompts.few_shot import FewShotPromptTemplate
from langchain.prompts.prompt import PromptTemplate

#è¿™é‡Œæˆ‘ä»¬ç”¨å­—å…¸æ¥è¡¨ç¤ºä¸€ä¸ªä¾‹å­ï¼Œæ¯ä¸ªç¤ºä¾‹éƒ½åº”è¯¥æ˜¯ä¸€ä¸ªå­—å…¸ï¼Œå…¶ä¸­é”®æ˜¯è¾“å…¥å˜é‡ï¼Œå€¼æ˜¯è¿™äº›è¾“å…¥å˜é‡çš„å€¼ã€‚
examples = [
  {
    "question": "Who lived longer, Muhammad Ali or Alan Turing?",
    "answer":
"""
Are follow up questions needed here: Yes.
Follow up: How old was Muhammad Ali when he died?
Intermediate answer: Muhammad Ali was 74 years old when he died.
Follow up: How old was Alan Turing when he died?
Intermediate answer: Alan Turing was 41 years old when he died.
So the final answer is: Muhammad Ali
"""
  },
  {
    "question": "When was the founder of craigslist born?",
    "answer":
"""
Are follow up questions needed here: Yes.
Follow up: Who was the founder of craigslist?
Intermediate answer: Craigslist was founded by Craig Newmark.
Follow up: When was Craig Newmark born?
Intermediate answer: Craig Newmark was born on December 6, 1952.
So the final answer is: December 6, 1952
"""
  },
  {
    "question": "Who was the maternal grandfather of George Washington?",
    "answer":
"""
Are follow up questions needed here: Yes.
Follow up: Who was the mother of George Washington?
Intermediate answer: The mother of George Washington was Mary Ball Washington.
Follow up: Who was the father of Mary Ball Washington?
Intermediate answer: The father of Mary Ball Washington was Joseph Ball.
So the final answer is: Joseph Ball
"""
  },
  {
    "question": "Are both the directors of Jaws and Casino Royale from the same country?",
    "answer":
"""
Are follow up questions needed here: Yes.
Follow up: Who is the director of Jaws?
Intermediate Answer: The director of Jaws is Steven Spielberg.
Follow up: Where is Steven Spielberg from?
Intermediate Answer: The United States.
Follow up: Who is the director of Casino Royale?
Intermediate Answer: The director of Casino Royale is Martin Campbell.
Follow up: Where is Martin Campbell from?
Intermediate Answer: New Zealand.
So the final answer is: No
"""
  }
]
```

####  ä½¿ç”¨ä¾‹å­é€‰æ‹©å™¨

åœ¨ä¸Šé¢çš„ä¾‹å­ä¸­ï¼Œæˆ‘ä»¬ä½¿ç”¨äº†ä¸€ä¸ªç®€å•çš„ä¾‹å­é€‰æ‹©å™¨ï¼Œå®ƒåªæ˜¯è¿”å›å…¨éƒ¨çš„ä¾‹å­ã€‚ä½†æ˜¯ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨è‡ªå®šä¹‰çš„ä¾‹å­é€‰æ‹©å™¨æ¥é€‰æ‹©ä¾‹å­ã€‚ä¾‹å¦‚ï¼Œæˆ‘ä»¬å¯ä»¥ä½¿ç”¨ä¸€ä¸ªä¾‹å­é€‰æ‹©å™¨ï¼Œè¯¥é€‰æ‹©å™¨å°†é€‰æ‹©ä¸è¾“å…¥æœ€ç›¸ä¼¼çš„ä¾‹å­ã€‚

###  MessagePromptTemplate**çš„ç±»å‹*

LangChainæä¾›ä¸åŒç±»å‹çš„ MessagePromptTemplate .æœ€å¸¸ç”¨çš„æ˜¯ AIMessagePromptTemplate å’Œ SystemMessagePromptTemplate HumanMessagePromptTemplate ï¼Œå®ƒä»¬åˆ†åˆ«åˆ›å»º AI æ¶ˆæ¯ã€ç³»ç»Ÿæ¶ˆæ¯å’Œäººç±»æ¶ˆæ¯ã€‚
ä½†æ˜¯ï¼Œå¦‚æœèŠå¤©æ¨¡å‹æ”¯æŒä½¿ç”¨ä»»æ„è§’è‰²æ¥æ”¶èŠå¤©æ¶ˆæ¯ï¼Œåˆ™å¯ä»¥ä½¿ç”¨ ChatMessagePromptTemplate ï¼Œå®ƒå…è®¸ç”¨æˆ·æŒ‡å®šè§’è‰²åç§°ã€‚

LangChain è¿˜æä¾›äº† MessagesPlaceholder ï¼Œå®ƒä½¿æ‚¨å¯ä»¥å®Œå…¨æ§åˆ¶åœ¨æ ¼å¼åŒ–è¿‡ç¨‹ä¸­è¦å‘ˆç°çš„æ¶ˆæ¯ã€‚
å½“æ‚¨ä¸ç¡®å®šåº”ä¸ºé‚®ä»¶æç¤ºæ¨¡æ¿ä½¿ç”¨ä»€ä¹ˆè§’è‰²æ—¶ï¼Œæˆ–è€…å½“æ‚¨å¸Œæœ›åœ¨æ ¼å¼åŒ–è¿‡ç¨‹ä¸­æ’å…¥é‚®ä»¶åˆ—è¡¨æ—¶ï¼Œè¿™å¯èƒ½å¾ˆæœ‰ç”¨ã€‚

```python
from langchain.prompts import MessagesPlaceholder,HumanMessagePromptTemplate,ChatPromptTemplate

human_prompt = "Summarize our conversation so far in {word_count} words."
human_message_template = HumanMessagePromptTemplate.from_template(human_prompt)

chat_prompt = ChatPromptTemplate.from_messages([MessagesPlaceholder(variable_name="conversation"), human_message_template])
```

```
from langchain.schema import HumanMessage,AIMessage
human_message = HumanMessage(content="What is the best way to learn programming?")
ai_message = AIMessage(content="""\
1. Choose a programming language: Decide on a programming language that you want to learn.

2. Start with the basics: Familiarize yourself with the basic programming concepts such as variables, data types and control structures.

3. Practice, practice, practice: The best way to learn programming is through hands-on experience\
""")

chat_prompt.format_prompt(conversation=[human_message, ai_message], word_count="10").to_messages()
```

###   åºåˆ—åŒ–å‚¨å­˜æç¤ºè¯

é€šå¸¸å»ºè®®å°†æç¤ºå­˜å‚¨ä¸ºæ–‡ä»¶ï¼Œè€Œä¸æ˜¯ python ä»£ç ã€‚
 è¿™å¯ä»¥è½»æ¾å…±äº«ã€å­˜å‚¨å’Œç‰ˆæœ¬æç¤ºã€‚
æœ¬ç¬”è®°æœ¬ä»‹ç»äº†å¦‚ä½•åœ¨ LangChain ä¸­æ‰§è¡Œæ­¤æ“ä½œï¼Œæ¼”ç»ƒäº†æ‰€æœ‰ä¸åŒç±»å‹çš„æç¤ºå’Œä¸åŒçš„åºåˆ—åŒ–é€‰é¡¹ã€‚
æ‰€æœ‰æç¤ºéƒ½æ˜¯é€šè¿‡`load_prompt`å‡½æ•°åŠ è½½çš„ã€‚

```python
from langchain.prompts import load_prompt
prompt = load_prompt("promptstore/simple_prompt.json")
print(prompt.format(adjective="funny", content="chickens"))
```

```python
#è¿™æ˜¾ç¤ºäº†ä» JSON åŠ è½½å‡ ä¸ªé•œå¤´ç¤ºä¾‹çš„ç¤ºä¾‹ã€‚
prompt = load_prompt("promptstore/few_shot_prompt.json")
print(prompt.format(adjective="funny"))
```

# å¤§è¯­è¨€æ¨¡å‹

*å¤§å‹è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰æ˜¯LangChainçš„æ ¸å¿ƒç»„ä»¶ã€‚LangChainä¸æä¾›è‡ªå·±çš„LLMï¼Œè€Œæ˜¯æä¾›äº†ä¸€ä¸ªæ ‡å‡†æ¥å£ï¼Œç”¨äºä¸è®¸å¤šä¸åŒçš„LLMè¿›è¡Œäº¤äº’ã€‚
https://python.langchain.com/docs/modules/model_io/models/llms/

## å¤§è¯­è¨€æ¨¡å‹çš„è·Ÿè¸ªä»¤ç‰Œä½¿ç”¨æƒ…å†µ
LangChainæä¾›äº†ä¸€ä¸ªæ–¹ä¾¿çš„æ–¹æ³•ï¼Œç”¨äºè·Ÿè¸ªLLMçš„ä»¤ç‰Œä½¿ç”¨æƒ…å†µã€‚è¿™å¯¹äºè°ƒè¯•æˆ–æ•™è‚²ç›®çš„éå¸¸æœ‰ç”¨ã€‚
ä»…é€‚ç”¨äºOpenAI APIã€‚

```python
from langchain.llms import OpenAI
from langchain.callbacks import get_openai_callback
llm = OpenAI(model_name="text-davinci-002", n=2, best_of=2,cache = None)

with get_openai_callback() as cb:
    result = llm("è®²ä¸ªç¬‘è¯")
    print(cb)
```



# è¾“å‡ºè§£æå™¨

è¯­è¨€æ¨¡å‹è¾“å‡ºæ–‡æœ¬ã€‚ä½†å¾ˆå¤šæ—¶å€™ï¼Œæ‚¨å¯èƒ½å¸Œæœ›è·å¾—æ›´ç»“æ„åŒ–çš„ä¿¡æ¯ï¼Œè€Œä¸ä»…ä»…æ˜¯æ–‡æœ¬å›å¤ã€‚è¿™å°±æ˜¯è¾“å‡ºè§£æå™¨çš„ç”¨æ­¦ä¹‹åœ°ã€‚
è¾“å‡ºåˆ†æå™¨æ˜¯å¸®åŠ©æ„å»ºè¯­è¨€æ¨¡å‹å“åº”çš„ç±»ã€‚è¾“å‡ºåˆ†æå™¨å¿…é¡»å®ç°ä¸¤ç§ä¸»è¦æ–¹æ³•ï¼š

â€œè·å–æ ¼å¼æŒ‡ä»¤â€ï¼šè¿”å›ä¸€ä¸ªå­—ç¬¦ä¸²çš„æ–¹æ³•ï¼Œå…¶ä¸­åŒ…å«æœ‰å…³å¦‚ä½•æ ¼å¼åŒ–è¯­è¨€æ¨¡å‹è¾“å‡ºçš„è¯´æ˜ã€‚

â€œParseâ€ï¼šä¸€ç§æ¥æ”¶å­—ç¬¦ä¸²ï¼ˆå‡è®¾æ˜¯æ¥è‡ªè¯­è¨€æ¨¡å‹çš„å“åº”ï¼‰å¹¶å°†å…¶è§£æä¸ºæŸç§ç»“æ„çš„æ–¹æ³•ã€‚

ç„¶åæ˜¯ä¸€ä¸ªå¯é€‰çš„ï¼š

â€œParse with promptâ€ï¼šä¸€ç§æ–¹æ³•ï¼Œå®ƒæ¥å—ä¸€ä¸ªå­—ç¬¦ä¸²ï¼ˆå‡è®¾æ˜¯æ¥è‡ªè¯­è¨€æ¨¡å‹çš„å“åº”ï¼‰å’Œä¸€ä¸ªæç¤ºï¼ˆå‡è®¾æ˜¯ç”Ÿæˆæ­¤ç±»å“åº”çš„æç¤ºï¼‰å¹¶å°†å…¶è§£æä¸ºæŸç§ç»“æ„ã€‚æç¤ºä¸»è¦åœ¨ OutputParser æƒ³è¦ä»¥æŸç§æ–¹å¼é‡è¯•æˆ–ä¿®å¤è¾“å‡ºæ—¶æä¾›ï¼Œå¹¶ä¸”éœ€è¦æ¥è‡ªæç¤ºçš„ä¿¡æ¯æ‰èƒ½æ‰§è¡Œæ­¤æ“ä½œã€‚

## åˆ—è¡¨è§£æå™¨

å½“æ‚¨æƒ³è¦è¿”å›é€—å·åˆ†éš”é¡¹çš„åˆ—è¡¨æ—¶ï¼Œå¯ä»¥ä½¿ç”¨æ­¤è¾“å‡ºåˆ†æå™¨ã€‚

```python
# å¯¼å…¥å¿…è¦çš„æ¨¡å—å’Œç±»
from langchain.output_parsers import CommaSeparatedListOutputParser
from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI

# åˆå§‹åŒ–ä¸€ä¸ªè§£æç”±é€—å·åˆ†éš”çš„åˆ—è¡¨çš„è§£æå™¨
output_parser = CommaSeparatedListOutputParser()

# è·å–è§£æå™¨çš„æ ¼å¼æŒ‡ä»¤
format_instructions = output_parser.get_format_instructions()

# å®šä¹‰æç¤ºæ¨¡æ¿ï¼Œç”¨äºç”Ÿæˆå…³äºç‰¹å®šä¸»é¢˜çš„ç”±é€—å·åˆ†éš”çš„åˆ—è¡¨
prompt = PromptTemplate(
    template="List five {subject}.\n{format_instructions}",
    input_variables=["subject"],
    partial_variables={"format_instructions": format_instructions}
)

# åˆå§‹åŒ–OpenAIæ¨¡å‹ï¼Œæ¸©åº¦è®¾ç½®ä¸º0ï¼ˆç”Ÿæˆçš„å›ç­”å°†æ›´åŠ ç¡®å®šï¼Œå°‘æœ‰éšæœºæ€§ï¼‰
model = OpenAI(temperature=0)

# æ ¼å¼åŒ–æç¤ºï¼Œè¿™é‡Œçš„ä¸»é¢˜æ˜¯â€œice cream flavorsâ€ï¼ˆå†°æ·‡æ·‹å£å‘³ï¼‰
_input = prompt.format(subject="å†°æ·‡æ·‹å£å‘³")

# ä½¿ç”¨æ¨¡å‹ç”Ÿæˆè¾“å‡º
output = model(_input)

# ä½¿ç”¨è§£æå™¨è§£æè¾“å‡º
output_parser.parse(output)
```

## æ—¥æœŸæ—¶é—´è§£æå™¨

æ­¤è¾“å‡ºè§£æå™¨æ˜¾ç¤ºå°†LLMè¾“å‡ºè§£æä¸ºæ—¥æœŸæ—¶é—´æ ¼å¼ã€‚

```python
# å¯¼å…¥å¿…è¦çš„æ¨¡å—å’Œç±»
from langchain.prompts import PromptTemplate
from langchain.output_parsers import DatetimeOutputParser
from langchain.chains import LLMChain
from langchain.llms import OpenAI

\# åˆå§‹åŒ–ä¸€ä¸ªæ—¥æœŸæ—¶é—´è¾“å‡ºè§£æå™¨
output_parser = DatetimeOutputParser()

\# å®šä¹‰æç¤ºæ¨¡æ¿ï¼Œç”¨äºå¼•å¯¼æ¨¡å‹å›ç­”ç”¨æˆ·çš„é—®é¢˜
template = """å›ç­”ç”¨æˆ·çš„é—®é¢˜:

{question}

{format_instructions}"""

\# ä½¿ç”¨æ¨¡æ¿åˆ›å»ºä¸€ä¸ªæç¤ºå®ä¾‹
prompt = PromptTemplate.from_template(
    template,
    partial_variables={"format_instructions": output_parser.get_format_instructions()},
)

\# åˆå§‹åŒ–ä¸€ä¸ªLLMChainï¼Œå®ƒç»“åˆäº†æç¤ºå’ŒOpenAIæ¨¡å‹æ¥ç”Ÿæˆè¾“å‡º
chain = LLMChain(prompt=prompt, llm=OpenAI())

\# è¿è¡Œé“¾æ¥è·å–å…³äºç‰¹å®šé—®é¢˜çš„ç­”æ¡ˆï¼Œè¿™é‡Œçš„é—®é¢˜æ˜¯â€œbitcoinæ˜¯ä»€ä¹ˆæ—¶å€™æˆç«‹çš„ï¼Ÿâ€
output = chain.run("bitcoinæ˜¯ä»€ä¹ˆæ—¶å€™æˆç«‹çš„ï¼Ÿç”¨è‹±æ–‡æ ¼å¼è¾“å‡ºæ—¶é—´")
```

##  æšä¸¾è§£æå™¨

```python
from langchain.output_parsers.enum import EnumOutputParser
from enum import Enum


class Colors(Enum):
    RED = "red"
    GREEN = "green"
    BLUE = "blue"

parser = EnumOutputParser(enum=Colors)
```

##     

```python
parser.parse("red")

# Can handle spaces
parser.parse(" green")

# And new lines
parser.parse("blue\n")

# And raises errors when appropriate
parser.parse("yellow")
```



##     5.4 è‡ªåŠ¨ä¿®å¤è§£æå™¨      

â€‹        æ­¤è¾“å‡ºè§£æå™¨åŒ…è£…å¦ä¸€ä¸ªè¾“å‡ºè§£æå™¨ï¼Œå¦‚æœç¬¬ä¸€ä¸ªè¾“å‡ºè§£æå™¨å¤±è´¥ï¼Œå®ƒä¼šè°ƒç”¨å¦ä¸€ä¸ª LLM ä»¥ä¿®å¤ä»»ä½•é”™è¯¯ã€‚      

â€‹        ä½†æ˜¯é™¤äº†æŠ›å‡ºé”™è¯¯ä¹‹å¤–ï¼Œæˆ‘ä»¬è¿˜å¯ä»¥åšå…¶ä»–äº‹æƒ…ã€‚å…·ä½“æ¥è¯´ï¼Œæˆ‘ä»¬å¯ä»¥å°†æ ¼å¼é”™è¯¯çš„è¾“å‡ºä»¥åŠæ ¼å¼åŒ–çš„æŒ‡ä»¤ä¼ é€’ç»™æ¨¡å‹ï¼Œå¹¶è¦æ±‚å®ƒä¿®å¤å®ƒã€‚      

```python
# å¯¼å…¥æ‰€éœ€çš„åº“å’Œæ¨¡å—
from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.output_parsers import PydanticOutputParser
from pydantic import BaseModel, Field, validator
from typing import List

\# å®šä¹‰ä¸€ä¸ªè¡¨ç¤ºæ¼”å‘˜çš„æ•°æ®ç»“æ„ï¼ŒåŒ…æ‹¬ä»–ä»¬çš„åå­—å’Œä»–ä»¬å‡ºæ¼”çš„ç”µå½±åˆ—è¡¨
class Actor(BaseModel):
    name: str = Field(description="name of an actor")                   # æ¼”å‘˜çš„åå­—
    film_names: List[str] = Field(description="list of names of films they starred in")  # ä»–ä»¬å‡ºæ¼”çš„ç”µå½±åˆ—è¡¨

\# å®šä¹‰ä¸€ä¸ªæŸ¥è¯¢ï¼Œç”¨äºæç¤ºç”Ÿæˆéšæœºæ¼”å‘˜çš„ç”µå½±ä½œå“åˆ—è¡¨
actor_query = "Generate the filmography for a random actor."

\# ä½¿ç”¨`Actor`æ¨¡å‹åˆå§‹åŒ–è§£æå™¨
parser = PydanticOutputParser(pydantic_object=Actor)

\# å®šä¹‰ä¸€ä¸ªæ ¼å¼é”™è¯¯çš„å­—ç¬¦ä¸²æ•°æ®
misformatted = "{'name': 'Tom Hanks', 'film_names': ['Forrest Gump']}"
# ä½¿ç”¨è§£æå™¨å°è¯•è§£æä¸Šè¿°æ•°æ®
parser.parse(misformatted)
```

```python
# è¦ä½¿misformattedå­—ç¬¦ä¸²æ­£ç¡®æ ¼å¼åŒ–ï¼Œæ‚¨éœ€è¦ç¡®ä¿å®ƒæ˜¯ä¸€ä¸ªæœ‰æ•ˆçš„JSONå­—ç¬¦ä¸²ã€‚è¿™æ„å‘³ç€æ‚¨åº”è¯¥ä½¿ç”¨åŒå¼•å·ï¼ˆ"ï¼‰è€Œä¸æ˜¯å•å¼•å·ï¼ˆ'ï¼‰æ¥åŒ…å›´é”®å’Œå€¼ã€‚ä»¥ä¸‹æ˜¯ä¿®æ”¹åçš„
parser.parse('{"name": "Tom Hanks", "film_names": ["Forrest Gump"]}')
```

```python
from langchain.output_parsers import OutputFixingParser

new_parser = OutputFixingParser.from_llm(parser=parser, llm=ChatOpenAI())
new_parser.parse(misformatted)
```


## ç»“æ„åŒ–è¾“å‡ºè§£æå™¨
å½“æ‚¨æƒ³è¦è¿”å›å¤šä¸ªå­—æ®µæ—¶ï¼Œå¯ä»¥ä½¿ç”¨æ­¤è¾“å‡ºåˆ†æå™¨ã€‚

è™½ç„¶ Pydantic/JSON è§£æå™¨åŠŸèƒ½æ›´å¼ºå¤§ï¼Œä½†æˆ‘ä»¬æœ€åˆå°è¯•ä½¿ç”¨ä»…åŒ…å«æ–‡æœ¬å­—æ®µçš„æ•°æ®ç»“æ„ã€‚

```python
# å¯¼å…¥å¿…è¦çš„æ¨¡å—å’Œç±»
from langchain.output_parsers import StructuredOutputParser, ResponseSchema
from langchain.prompts import PromptTemplate, ChatPromptTemplate, HumanMessagePromptTemplate
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI

# å®šä¹‰å“åº”æ¨¡å¼ï¼Œç”¨äºæŒ‡å¯¼æ¨¡å‹æä¾›ç‰¹å®šç±»å‹çš„è¾“å‡º
response_schemas = [
    ResponseSchema(name="answer", description="å›ç­”ç”¨æˆ·çš„é—®é¢˜"),
    ResponseSchema(name="source", description="å›ç­”ç”¨æˆ·é—®é¢˜çš„æ¥æºï¼Œåº”ä¸ºä¸€ä¸ªç½‘ç«™ã€‚")
]

# ä½¿ç”¨å“åº”æ¨¡å¼åˆå§‹åŒ–ä¸€ä¸ªç»“æ„åŒ–è¾“å‡ºè§£æå™¨
output_parser = StructuredOutputParser.from_response_schemas(response_schemas)

# è·å–è§£æå™¨çš„æ ¼å¼æŒ‡ä»¤
format_instructions = output_parser.get_format_instructions()

# å®šä¹‰æç¤ºæ¨¡æ¿ï¼Œç”¨äºå¼•å¯¼æ¨¡å‹æ ¹æ®ç”¨æˆ·çš„é—®é¢˜æä¾›ç­”æ¡ˆåŠç­”æ¡ˆçš„æ¥æº
prompt = PromptTemplate(
    template="å°½å¯èƒ½å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n{format_instructions}\n{question}",
    input_variables=["question"],
    partial_variables={"format_instructions": format_instructions}
)

# åˆå§‹åŒ–OpenAIæ¨¡å‹ï¼Œæ¸©åº¦è®¾ç½®ä¸º0ï¼ˆç”Ÿæˆçš„å›ç­”å°†æ›´åŠ ç¡®å®šï¼Œå°‘æœ‰éšæœºæ€§ï¼‰
model = OpenAI(temperature=0)

# æ ¼å¼åŒ–æç¤ºï¼Œè¿™é‡Œçš„é—®é¢˜æ˜¯â€œæ³•å›½çš„é¦–éƒ½æ˜¯ä»€ä¹ˆï¼Ÿâ€
_input = prompt.format_prompt(question="æ³•å›½çš„é¦–éƒ½æ˜¯ä»€ä¹ˆï¼Ÿ")

# ä½¿ç”¨æ¨¡å‹ç”Ÿæˆè¾“å‡º
output = model(_input.to_string())

# ä½¿ç”¨è§£æå™¨è§£æè¾“å‡º
output_parser.parse(output)
```

```python
# å¯¼å…¥å¿…è¦çš„æ¨¡å—å’Œç±»
from langchain.chat_models import ChatOpenAI
from langchain.prompts import ChatPromptTemplate, HumanMessagePromptTemplate

# åˆå§‹åŒ–èŠå¤©æ¨¡å‹ï¼Œæ¸©åº¦è®¾ç½®ä¸º0ï¼ˆç”Ÿæˆçš„å›ç­”å°†æ›´åŠ ç¡®å®šï¼Œå°‘æœ‰éšæœºæ€§ï¼‰
chat_model = ChatOpenAI(temperature=0)

# å®šä¹‰èŠå¤©æç¤ºæ¨¡æ¿ï¼Œè¯¥æ¨¡æ¿åŒ…å«ä¸€ç³»åˆ—çš„æ¶ˆæ¯å¯¹è±¡
# è¿™é‡Œæˆ‘ä»¬åªå®šä¹‰ä¸€ä¸ªæ¶ˆæ¯ï¼Œè¯¥æ¶ˆæ¯æç¤ºæ¨¡å‹å°½å¯èƒ½åœ°å›ç­”ç”¨æˆ·çš„é—®é¢˜
prompt = ChatPromptTemplate(
    messages=[
        HumanMessagePromptTemplate.from_template("å°½å¯èƒ½å›ç­”ç”¨æˆ·çš„é—®é¢˜ã€‚\n{format_instructions}\n{question}")
    ],
    input_variables=["question"],
    partial_variables={"format_instructions": format_instructions}
)

# æ ¼å¼åŒ–æç¤ºï¼Œè¿™é‡Œçš„é—®é¢˜æ˜¯â€œæ³•å›½çš„é¦–éƒ½æ˜¯ä»€ä¹ˆï¼Ÿâ€
_input = prompt.format_prompt(question="æ³•å›½çš„é¦–éƒ½æ˜¯ä»€ä¹ˆï¼Ÿ")

# ä½¿ç”¨èŠå¤©æ¨¡å‹ç”Ÿæˆè¾“å‡º
output = chat_model(_input.to_messages())

# ä½¿ç”¨è§£æå™¨è§£æè¾“å‡ºçš„å†…å®¹
output_parser.parse(output.content)
```



# æ–‡æ¡£åŠ è½½å™¨      

è®¸å¤šLLMåº”ç”¨ç¨‹åºéœ€è¦ç”¨æˆ·ç‰¹å®šçš„æ•°æ®ï¼Œè¿™äº›æ•°æ®ä¸å±äºæ¨¡å‹çš„è®­ç»ƒé›†ã€‚

å®ç°æ­¤ç›®çš„çš„ä¸»è¦æ–¹æ³•æ˜¯é€šè¿‡æ£€ç´¢å¢å¼ºç”Ÿæˆ ï¼ˆRAGï¼‰ã€‚åœ¨æ­¤è¿‡ç¨‹ä¸­ï¼Œæ£€ç´¢å¤–éƒ¨æ•°æ®ï¼Œç„¶ååœ¨æ‰§è¡Œç”Ÿæˆæ­¥éª¤æ—¶ä¼ é€’ç»™LLMã€‚

LangChainä¸ºRAGåº”ç”¨ç¨‹åºæä¾›äº†æ‰€æœ‰æ„å»ºå— - ä»ç®€å•åˆ°å¤æ‚ã€‚æ–‡æ¡£çš„è¿™ä¸€éƒ¨åˆ†æ¶µç›–äº†ä¸æ£€ç´¢æ­¥éª¤ç›¸å…³çš„æ‰€æœ‰å†…å®¹ - ä¾‹å¦‚æ•°æ®çš„è·å–ã€‚

è™½ç„¶è¿™å¬èµ·æ¥å¾ˆç®€å•ï¼Œä½†å®ƒå¯èƒ½éå¸¸å¤æ‚ã€‚è¿™åŒ…æ‹¬å‡ ä¸ªå…³é”®æ¨¡å—ã€‚



ä»è®¸å¤šä¸åŒçš„æ¥æºåŠ è½½æ–‡æ¡£ã€‚LangChainæä¾›äº†100å¤šç§ä¸åŒçš„æ–‡æ¡£åŠ è½½å™¨ï¼Œä»¥åŠä¸è¯¥é¢†åŸŸå…¶ä»–ä¸»è¦æä¾›å•†çš„é›†æˆï¼Œå¦‚AirByteå’ŒUnstructuredã€‚

æˆ‘ä»¬æä¾›é›†æˆï¼Œä»æ‰€æœ‰ç±»å‹çš„ä½ç½®ï¼ˆç§æœ‰ s3 å­˜å‚¨æ¡¶ã€å…¬å…±ç½‘ç«™ï¼‰åŠ è½½æ‰€æœ‰ç±»å‹çš„æ–‡æ¡£ï¼ˆhtmlã€PDFã€ä»£ç ï¼‰ã€‚

ä½¿ç”¨æ–‡æ¡£åŠ è½½å™¨ä»¥ çš„å½¢å¼ä» Document æºåŠ è½½æ•°æ®ã€‚



A Document æ˜¯ä¸€æ®µæ–‡æœ¬å’Œå…³è”çš„å…ƒæ•°æ®ã€‚

ä¾‹å¦‚ï¼Œæœ‰ç”¨äºåŠ è½½ç®€å• .txt æ–‡ä»¶ã€åŠ è½½ä»»ä½•ç½‘é¡µçš„æ–‡æœ¬å†…å®¹ç”šè‡³åŠ è½½ YouTube è§†é¢‘è„šæœ¬çš„æ–‡æ¡£åŠ è½½å™¨ã€‚

æ–‡æ¡£åŠ è½½ç¨‹åºå…¬å¼€ä¸€ä¸ªâ€œåŠ è½½â€æ–¹æ³•ï¼Œç”¨äºå°†æ•°æ®ä½œä¸ºæ–‡æ¡£ä»é…ç½®çš„æºåŠ è½½ã€‚å®ƒä»¬è¿˜å¯ä»¥é€‰æ‹©å®ç°â€œå»¶è¿ŸåŠ è½½â€ï¼Œä»¥ä¾¿å°†æ•°æ®å»¶è¿ŸåŠ è½½åˆ°å†…å­˜ä¸­ã€‚

```python
from langchain.document_loaders import TextLoader

loader = TextLoader("documentstore/index.md")
```

åŠ è½½ CSV æ•°æ®ï¼Œæ¯ä¸ªæ–‡æ¡£ä¸€è¡Œã€‚

```python
from langchain.document_loaders.csv_loader import CSVLoader



loader = CSVLoader(file_path='documentstore/index.csv')
data = loader.load()
```

è‡ªå®šä¹‰ csv è§£æå’ŒåŠ è½½

```python
loader = CSVLoader(file_path='documentstore/index.csv', csv_args={
    'delimiter': ',',
    'quotechar': '"',
    'fieldnames': ['title','context']
})

data = loader.load()
```

ä½¿ç”¨è¯¥ source_column å‚æ•°ä¸ºä»æ¯ä¸€è¡Œåˆ›å»ºçš„æ–‡æ¡£æŒ‡å®šæºã€‚å¦åˆ™ file_path å°†ç”¨ä½œä» CSV æ–‡ä»¶åˆ›å»ºçš„æ‰€æœ‰æ–‡æ¡£çš„æºã€‚

```python
loader = CSVLoader(file_path='documentstore/index.csv', source_column="context")

data = loader.load()
```

æ›´æ”¹åŠ è½½ç¨‹åºç±»

```python
from langchain.document_loaders import PythonLoader
loader = DirectoryLoader('E:\\pycharmproject\\LangChainStudyProject\\LangChainStudyProject', glob="*.py", loader_cls=PythonLoader)
docs = loader.load()
```



# æ–‡æ¡£è½¬æ¢å™¨      

åŠ è½½æ–‡æ¡£åï¼Œæ‚¨é€šå¸¸éœ€è¦è½¬æ¢å®ƒä»¬ä»¥æ›´å¥½åœ°é€‚åˆæ‚¨çš„åº”ç”¨ç¨‹åºã€‚

æœ€ç®€å•çš„ç¤ºä¾‹æ˜¯ï¼Œæ‚¨å¯èƒ½å¸Œæœ›å°†é•¿æ–‡æ¡£æ‹†åˆ†ä¸ºå¯ä»¥æ”¾å…¥æ¨¡å‹ä¸Šä¸‹æ–‡çª—å£çš„è¾ƒå°å—ã€‚

LangChain æœ‰è®¸å¤šå†…ç½®çš„æ–‡æ¡£è½¬æ¢å™¨ï¼Œå¯ä»¥è½»æ¾æ‹†åˆ†ã€ç»„åˆã€è¿‡æ»¤å’Œä»¥å…¶ä»–æ–¹å¼æ“ä½œæ–‡æ¡£ã€‚
å½“æ‚¨æƒ³è¦å¤„ç†é•¿æ–‡æœ¬æ—¶ï¼Œæœ‰å¿…è¦å°†è¯¥æ–‡æœ¬æ‹†åˆ†ä¸ºå—ã€‚

å¬èµ·æ¥å¾ˆç®€å•ï¼Œä½†è¿™é‡Œæœ‰å¾ˆå¤šæ½œåœ¨çš„å¤æ‚æ€§ã€‚

ç†æƒ³æƒ…å†µä¸‹ï¼Œæ‚¨å¸Œæœ›å°†è¯­ä¹‰ç›¸å…³çš„æ–‡æœ¬ç‰‡æ®µæ”¾åœ¨ä¸€èµ·ã€‚

â€œè¯­ä¹‰ç›¸å…³â€çš„å«ä¹‰å¯èƒ½å–å†³äºæ–‡æœ¬çš„ç±»å‹ã€‚æœ¬ç¬”è®°æœ¬å±•ç¤ºäº†å®ç°æ­¤ç›®çš„çš„å‡ ç§æ–¹æ³•ã€‚

é»˜è®¤æ¨èçš„æ–‡æœ¬æ‹†åˆ†å™¨æ˜¯ RecursiveCharacterTextSplitterã€‚æ­¤æ–‡æœ¬æ‹†åˆ†å™¨é‡‡ç”¨å­—ç¬¦åˆ—è¡¨ã€‚å®ƒå°è¯•åŸºäºç¬¬ä¸€ä¸ªå­—ç¬¦çš„æ‹†åˆ†æ¥åˆ›å»ºå—ï¼Œä½†å¦‚æœä»»ä½•å—å¤ªå¤§ï¼Œå®ƒå°±ä¼šç§»åŠ¨åˆ°ä¸‹ä¸€ä¸ªå­—ç¬¦ï¼Œä¾æ­¤ç±»æ¨ã€‚é»˜è®¤æƒ…å†µä¸‹ï¼Œå®ƒå°è¯•æ‹†åˆ†çš„å­—ç¬¦æ˜¯ ["\n\n", "\n", " ", ""]

### text_splitter

```python
# This is a long document we can split up.
with open('documentstore/state_of_the_union.txt') as f:
    state_of_the_union = f.read()

from langchain.text_splitter import RecursiveCharacterTextSplitter
text_splitter = RecursiveCharacterTextSplitter(
    # Set a really small chunk size, just to show.
    chunk_size = 100,
    chunk_overlap  = 20,
    length_function = len,
    add_start_index = True,
)
texts = text_splitter.create_documents([state_of_the_union])
print(texts[0])
print(texts[1])
```

ä¸‹é¢æ˜¯å°†å…ƒæ•°æ®ä¸æ–‡æ¡£ä¸€èµ·ä¼ é€’çš„ç¤ºä¾‹ï¼Œè¯·æ³¨æ„ï¼Œå…ƒæ•°æ®ä¸æ–‡æ¡£ä¸€èµ·æ‹†åˆ†ã€‚

```python
metadatas = [{"document": 1}, {"document": 2}]
documents = text_splitter.create_documents([state_of_the_union, state_of_the_union], metadatas=metadatas)
print(documents[0])
```

### CodeTextSplitter 

CodeTextSplitter å…è®¸æ‚¨ä½¿ç”¨å¤šç§è¯­è¨€æ”¯æŒæ‹†åˆ†ä»£ç ã€‚å¯¼å…¥æšä¸¾ Language å¹¶æŒ‡å®šè¯­è¨€ã€‚

```python
from langchain.text_splitter import (
    RecursiveCharacterTextSplitter,
    Language,
)
# Full list of support languages
[e.value for e in Language]
```

###  PythonTextSplitter

ä¸‹é¢æ˜¯ä¸€ä¸ªä½¿ç”¨ PythonTextSplitter çš„ç¤ºä¾‹

```python
PYTHON_CODE = """
def hello_world():
    print("Hello, World!")

\# Call the function
hello_world()
"""
python_splitter = RecursiveCharacterTextSplitter.from_language(
    language=Language.PYTHON, chunk_size=50, chunk_overlap=0
)
python_docs = python_splitter.create_documents([PYTHON_CODE])
python_docs
```

### js_splitter 

ä¸‹é¢æ˜¯ä¸€ä¸ªä½¿ç”¨ JS æ–‡æœ¬æ‹†åˆ†å™¨çš„ç¤ºä¾‹

```
JS_CODE = """
function helloWorld() {
  console.log("Hello, World!");
}

// Call the function
helloWorld();
"""

js_splitter = RecursiveCharacterTextSplitter.from_language(
    language=Language.JS, chunk_size=60, chunk_overlap=0
)
js_docs = js_splitter.create_documents([JS_CODE])
```

### Markdown



~~~python
markdown_text = """
# ğŸ¦œï¸ğŸ”— LangChain

âš¡ Building applications with LLMs through composability âš¡

## Quick Install

```bash
# Hopefully this code block isn't split
pip install langchain
```

As an open source project in a rapidly developing field, we are extremely open to contributions.
"""
md_splitter = RecursiveCharacterTextSplitter.from_language(
    language=Language.MARKDOWN, chunk_size=60, chunk_overlap=0
)
md_docs = md_splitter.create_documents([markdown_text])
~~~

### æŒ‰å­—ç¬¦é€’å½’æ‹†åˆ†

```
from langchain.text_splitter import RecursiveCharacterTextSplitter
# This is a long document we can split up.
with open('documentstore/state_of_the_union.txt') as f:
    state_of_the_union = f.read()
text_splitter = RecursiveCharacterTextSplitter(
    # Set a really small chunk size, just to show.
    chunk_size = 100,
    chunk_overlap  = 20,
    length_function = len,
)
texts = text_splitter.create_documents([state_of_the_union])
print(texts[0])
print(texts[1])
```



##  æ–‡æœ¬åµŒå…¥æ¨¡å‹
åµŒå…¥ç±»æ˜¯è®¾è®¡ç”¨äºä¸æ–‡æœ¬åµŒå…¥æ¨¡å‹æ¥å£çš„ç±»ã€‚æœ‰å¾ˆå¤šåµŒå…¥æ¨¡å‹æä¾›ç¨‹åºï¼ˆOpenAIï¼ŒCohereï¼ŒHugging Faceç­‰ï¼‰ - è¿™ä¸ªç±»æ—¨åœ¨ä¸ºæ‰€æœ‰å®ƒä»¬æä¾›ä¸€ä¸ªæ ‡å‡†æ¥å£ã€‚

åµŒå…¥åˆ›å»ºä¸€æ®µæ–‡æœ¬çš„çŸ¢é‡è¡¨ç¤ºå½¢å¼ã€‚è¿™å¾ˆæœ‰ç”¨ï¼Œå› ä¸ºè¿™æ„å‘³ç€æˆ‘ä»¬å¯ä»¥è€ƒè™‘å‘é‡ç©ºé—´ä¸­çš„æ–‡æœ¬ï¼Œå¹¶æ‰§è¡Œè¯¸å¦‚è¯­ä¹‰æœç´¢ä¹‹ç±»çš„æ“ä½œï¼Œåœ¨å…¶ä¸­æˆ‘ä»¬å¯»æ‰¾å‘é‡ç©ºé—´ä¸­æœ€ç›¸ä¼¼çš„æ–‡æœ¬ç‰‡æ®µã€‚

LangChain ä¸­çš„åŸºæœ¬åµŒå…¥ç±»å…¬å¼€äº†ä¸¤ç§æ–¹æ³•ï¼šä¸€ç§ç”¨äºåµŒå…¥æ–‡æ¡£ï¼Œå¦ä¸€ç§ç”¨äºåµŒå…¥æŸ¥è¯¢ã€‚å‰è€…å°†å¤šä¸ªæ–‡æœ¬ä½œä¸ºè¾“å…¥ï¼Œè€Œåè€…åˆ™é‡‡ç”¨å•ä¸ªæ–‡æœ¬ã€‚å°†å®ƒä»¬ä½œä¸ºä¸¤ä¸ªç‹¬ç«‹æ–¹æ³•çš„åŸå› æ˜¯ï¼ŒæŸäº›åµŒå…¥æä¾›ç¨‹åºå¯¹æ–‡æ¡£ï¼ˆè¦æœç´¢ï¼‰å’ŒæŸ¥è¯¢ï¼ˆæœç´¢æŸ¥è¯¢æœ¬èº«ï¼‰å…·æœ‰ä¸åŒçš„åµŒå…¥æ–¹æ³•ã€‚

```python
from langchain.embeddings import OpenAIEmbeddings

embeddings_model = OpenAIEmbeddings()

embeddings = embeddings_model.embed_documents(
    [
        "Hi there!",
        "Oh, hello!",
        "What's your name?",
        "My friends call me World",
        "Hello World!"
    ]
)
len(embeddings), len(embeddings[0])
```

> åµŒå…¥å¯ä»¥å­˜å‚¨æˆ–ä¸´æ—¶ç¼“å­˜ï¼Œä»¥é¿å…éœ€è¦é‡æ–°è®¡ç®—å®ƒä»¬ã€‚

```python
from langchain.storage import InMemoryStore, LocalFileStore
from langchain.embeddings import OpenAIEmbeddings, CacheBackedEmbeddings
from langchain.document_loaders import TextLoader
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.text_splitter import CharacterTextSplitter
from langchain.vectorstores import FAISS
underlying_embeddings = OpenAIEmbeddings()
fs = LocalFileStore("./cache/")

cached_embedder = CacheBackedEmbeddings.from_bytes_store(
    underlying_embeddings, fs, namespace=underlying_embeddings.model
)
```

åŠ è½½æ–‡æ¡£ï¼Œå°†å…¶æ‹†åˆ†ä¸ºå—ï¼ŒåµŒå…¥æ¯ä¸ªå—å¹¶å°†å…¶åŠ è½½åˆ°çŸ¢é‡å­˜å‚¨ä¸­ã€‚

```python
raw_documents = TextLoader("documentstore/state_of_the_union.txt").load()
text_splitter = CharacterTextSplitter(chunk_size=1000, chunk_overlap=0)
documents = text_splitter.split_documents(raw_documents)
#create the vectorstore åˆ›å»ºçŸ¢é‡å­˜å‚¨
db = FAISS.from_documents(documents, cached_embedder)
```

å¦‚æœæˆ‘ä»¬å°è¯•å†æ¬¡åˆ›å»º vectostoreï¼Œå®ƒä¼šå¿«å¾—å¤šï¼Œå› ä¸ºå®ƒä¸éœ€è¦é‡æ–°è®¡ç®—ä»»ä½•åµŒå…¥ã€‚

```python
db2 = FAISS.from_documents(documents, cached_embedder)
```

```python
store = InMemoryStore()
underlying_embeddings = OpenAIEmbeddings()
embedder = CacheBackedEmbeddings.from_bytes_store(
    underlying_embeddings, store, namespace=underlying_embeddings.model
)
embeddings = embedder.embed_documents(["hello", "goodbye"])
```

# å‘é‡æ•°æ®åº“

å­˜å‚¨å’Œæœç´¢éç»“æ„åŒ–æ•°æ®çš„æœ€å¸¸è§æ–¹æ³•ä¹‹ä¸€æ˜¯åµŒå…¥å®ƒå¹¶å­˜å‚¨ç”Ÿæˆçš„åµŒå…¥å‘é‡ï¼Œ

ç„¶ååœ¨æŸ¥è¯¢æ—¶åµŒå…¥éç»“æ„åŒ–æŸ¥è¯¢å¹¶æ£€ç´¢ä¸åµŒå…¥æŸ¥è¯¢â€œæœ€ç›¸ä¼¼â€çš„åµŒå…¥å‘é‡ã€‚

çŸ¢é‡å­˜å‚¨è´Ÿè´£å­˜å‚¨åµŒå…¥æ•°æ®å¹¶ä¸ºæ‚¨æ‰§è¡ŒçŸ¢é‡æœç´¢ã€‚

```python
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.vectorstores import Chroma
\# ä½¿ç”¨å‘é‡æ•°æ®åº“chromaï¼Œåˆ©ç”¨openaiçš„embaddingå¯¹æ–‡æœ¬è¿›è¡Œå‘é‡åŒ–
db = Chroma.from_texts(list_text, OpenAIEmbeddings())
```

> ç›¸ä¼¼æ€§æœç´¢

```python
query = "å®¢æˆ·çš„èº«ä»½è¯å·æ˜¯å¤šå°‘"
docs = db.similarity_search(query)
print(docs[0].page_content)
```

æŒ‰å‘é‡æœç´¢ç›¸ä¼¼æ€§

```python
embedding_vector = OpenAIEmbeddings().embed_query(query)
print(f'embedding_vectorï¼š{embedding_vector}')
docs = db.similarity_search_by_vector(embedding_vector)
print(docs[0].page_content)
```

ä¿å­˜å’ŒåŠ è½½

```
db.save_local("faiss_index")
new_db = FAISS.load_local("faiss_index", OpenAIEmbeddings())
```

