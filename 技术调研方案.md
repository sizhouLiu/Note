# 技术调研方案

----

## 自动操作浏览器：

## RPA工具 ： 

### 影刀

影刀的功能很好 很多功能都可以做到开箱即用 虽然有些地方并且内置了一个3.7的Python解释器也可以内嵌Js 对Python也有不错的支持 但是社区版只能分享三十行的一个流程工具，查了一下有解决办法  就是把流程文件复制打包然后发送给他人在电脑上部署（好像最新版把这个漏洞堵住了）

企业版定价不清楚

如果企业版定价不算离谱的话 其实可以买一个  挺方便的说实话

### UiBot

----


![image-20241221163828950](https://stupid-blog-img.oss-cn-beijing.aliyuncs.com/Blog/image-20241221163828950.png)



### quicker

![image-20241221163724566](https://stupid-blog-img.oss-cn-beijing.aliyuncs.com/Blog/image-20241221163724566.png)

### selenium

---

selenium是一个用来操作浏览器的框架 依赖几个内核的驱动 不方便分发部署 但是功能都集中在Python脚本里 方便后续的APi接入 

好处是开发起来比较方便 并且可以结合一部分Api的逆向





### 油猴

油猴主要是靠Js操作浏览器 页面元素 分发方便 只需要上架然后大家下载油猴 安装脚本就可以 唯一的问题是我Js写的少 有一定的学习成本 开发效率也可能会低一些...



### 接口

通过逆向Boss的接口进行纯接口请求

优点：部署方便 可以部署到一台服务器上 不用给客服分发  效率高（不过这些业务不需要高性能需求）

缺点：由于走接口 开发效率比较低  并且有一定的开发风险 不确定会不会因为某些加密的问题卡住  以及session分发的问题 可能会被封号 封IP  





# 大模型

## 自建可能性：

目前 4090GPU服务器一个月大约是1800 勉强可以跑起来8B的模型 每秒大约110token （tongyi7b） 调用Api拿到的应该是140b的模型 泛化性和生成性更强

当然可以本地起一个llama8b 用cpu做推理 但是部署还是很麻烦 用docker拉镜像还需要给每个电脑装docker 总结是 当前业务量完全没有必要自建 业务没大到每小时50块钱token前 自建没意义 而且现在基础模型的token和不要钱差不多



## 文心一言

-----

  我对文心一言其实有些偏见 百度的Ai起步非常早 但是使用体验非常差  半年前百度的比赛用文心一言构建Agent工具 把百度百科的数据给他 结果输出很差 对于内容没有总结- 但是 既然之前用的是文心一言其实搞两套账号使用维护也不是特别方便



## 通义千问

---

当前国内大模型领域 通义应该是做的比较好的一批

| **模型服务**                                                 | **模型规格**          | **输入（input）价格**                                  | **输出（output）价格**                                |
| ------------------------------------------------------------ | --------------------- | ------------------------------------------------------ | ----------------------------------------------------- |
| Qwen-Long                                                    | qwen-long             | 0.0005元/1,000 tokens                                  | 0.002元/1,000 tokens                                  |
| 通义千问-Turbo                                               | qwen-turbo            | 0.0003元/1,000 tokensBatch调用：0.00015元/1,000 tokens | 0.0006元/1,000 tokensBatch调用：0.0003元/1,000 tokens |
| qwen-turbo-latest                                            | 0.0003元/1,000 tokens | 0.0006元/1,000                                         |                                                       |
| qwen-turbo-2024-09-19（qwen-turbo-0919）当前等同qwen-turbo-latest |                       |                                                        |                                                       |
| qwen-turbo-2024-06-24（qwen-turbo-0624）                     |                       |                                                        |                                                       |
| qwen-turbo-2024-02-06（qwen-turbo-0206）                     | 0.002元/1,000 tokens  | 0.006元/1,000                                          |                                                       |
| 通义千问-Plus                                                | qwen-plus             | 0.0008元/1,000 tokensBatch调用：0.0004元/1,000 tokens  | 0.002元/1,000 tokensBatch调用：0.001元/1,000 tokens   |
| qwen-plus-latest                                             | 0.0008元/1,000 tokens | 0.002元/1,000 tokens                                   |                                                       |
| qwen-plus-2024-09-19(qwen-plus-0919)当前等同qwen-plus-latest |                       |                                                        |                                                       |
| qwen-plus-2024-08-06（qwen-plus-0806）                       | 0.004元/1,000 tokens  | 0.012元/1,000 tokens                                   |                                                       |
| qwen-plus-2024-07-23（qwen-plus-0723）                       |                       |                                                        |                                                       |
| qwen-plus-2024-06-24（qwen-plus-0624）                       |                       |                                                        |                                                       |
| qwen-plus-2024-02-06（qwen-plus-0206）                       |                       |                                                        |                                                       |
| 通义千问-Max                                                 | qwen-max              | 0.02元/1,000 tokensBatch调用：0.01元/1,000 tokens      | 0.06元/1,000 tokensBatch调用：0.03元/1,000 tokens     |
| qwen-max-latest                                              | 0.02元/1,000 tokens   | 0.06元/1,000 tokens                                    |                                                       |
| qwen-max-2024-09-19(qwen-max-0919)当前等同qwen-max-latest    |                       |                                                        |                                                       |
| qwen-max-2024-04-28（qwen-max-0428）                         | 0.04元/1,000 tokens   | 0.12元/1,000 tokens                                    |                                                       |
| qwen-max-2024-04-03（qwen-max-0403）                         |                       |                                                        |                                                       |
| qwen-max-2024-01-07（qwen-max-0107）                         |                       |                                                        |                                                       |

## kimi

----

kimi作为大模型独角兽的生成质量也很不错 语言理解和和多功能文档拆分查询也还很好 不过目前的业务可能用不到这些功能

![image-20241221174145039](https://stupid-blog-img.oss-cn-beijing.aliyuncs.com/Blog/image-20241221174145039.png)